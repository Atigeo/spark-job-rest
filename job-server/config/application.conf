# Settings for safe local mode development
spark {
  master = "mesos://127.0.1.1:5050"

  jobserver {
    port = 8090

    # Number of job results to keep per JobResultActor/context
    job-result-cache-size = 5000

    jobdao = spark.jobserver.io.JobFileDAO

    jobserverjar = /full_path_to_project/job-server/target/spark-job-rest.jar

    jobmanagerjar = /full_path_to_project/job-manager-helper/target/job-manager-helper-0.3.1.jar

    akkajar = /full_path_to_project/akka-app/target/akka.jar

    mesosjar = /full_path_to_home_folder/.ivy2/cache/org.apache.mesos/mesos/jars/mesos-0.19.0.jar

    mesoshelperjar = /full_path_to_project/mesos-loader/target/mesos-loader-0.3.1.jar


    filedao {
      rootdir = /tmp/spark-job-rest/filedao/data
    }

    # Time out for job server to wait while creating contexts
    context-creation-timeout = 45 s

    # A zero-arg class implementing spark.jobserver.util.SparkContextFactory
    context-factory = spark.jobserver.util.DefaultSparkContextFactory
  }

  # predefined Spark contexts
  # Below is an example, but do not uncomment it.   Everything defined here is carried over to
  # deploy-time configs, so they will be created in all environments.  :(
  contexts {
    # abc-demo {
    #   num-cpu-cores = 4            # Number of cores to allocate.  Required.
    #   memory-per-node = 1024m      # Executor memory per node, -Xmx style eg 512m, 1G, etc.
    # }
    # define additional contexts here
  }

  # Default settings for ad hoc as well as manually created contexts
  # You can add any Spark config params here, for example, spark.mesos.coarse = true
  context-settings {
    num-cpu-cores = 4           # Number of cores to allocate.  Required.
    memory-per-node = 512m      # Executor memory per node, -Xmx style eg 512m, 1G, etc.
   # max-jobs-per-context = 4  # Max # of jobs to run at the same time

   # spark.tachyonStore.url = "tachyon://tachyonMaster:19998"
    spark.shuffle.consolidateFiles = true
    spark.storage.memoryFraction = 0.4
    spark.shuffle.memoryFraction = 0.5
    spark.default.parallelism = 128
   # spark.eventLog.enabled = true
   # spark.eventLog.dir = "hdfs://namenodeIp:8020/spark"
    spark.akka.threads = 128
    spark.akka.frameSize = 100

  }
  home = "/full_path_to_spark_home"
}

akka {
  # Use SLF4J/logback for deployed environment logging
  loggers = ["akka.event.slf4j.Slf4jLogger"]
}

# check the reference.conf in spray-can/src/main/resources for all defined settings
spray.can.server {
  # uncomment the next line for making this an HTTPS example
  # ssl-encryption = on
  idle-timeout = 40 s
  request-timeout = 35 s
  pipelining-limit = 2 # for maximum performance (prevents StopReading / ResumeReading messages to the IOBridge)
  # Needed for HTTP/1.0 requests with missing Host headers
  default-host-header = "spray.io:8765"
}

front{
akka {
  loglevel = "DEBUG"
  actor {
    provider = "akka.remote.RemoteActorRefProvider"
  }
  remote {
     enabled-transports = ["akka.remote.netty.tcp"]
    log-sent-messages = on
    log-received-messages = on
    netty.tcp {
       maximum-frame-size = 512000b
     //transport-class = "akka.remote.transport.netty.NettyTransport"
      hostname = "localhost"
      port = 14044
    }
  }
}
}


akka {
  loglevel = "DEBUG"
  stdout-loglevel = "DEBUG"
  actor {
    provider = "akka.remote.RemoteActorRefProvider"
    debug {
          # enable function of Actor.loggable(), which is to log any received message
          # at DEBUG level, see the “Testing Actor Systems” section of the Akka
          # Documentation at http://akka.io/docs
          receive = off

          # enable DEBUG logging of all AutoReceiveMessages (Kill, PoisonPill et.c.)
          autoreceive = off

          # enable DEBUG logging of actor lifecycle changes
          lifecycle = off

          # enable DEBUG logging of all LoggingFSMs for events, transitions and timers
          fsm = off

          # enable DEBUG logging of subscription changes on the eventStream
          event-stream = off

          # enable DEBUG logging of unhandled messages
          unhandled = off

          # enable WARN logging of misconfigured routers
          router-misconfiguration = off
        }
  }
  remote {
     enabled-transports = ["akka.remote.netty.tcp"]
    log-sent-messages = on
    log-received-messages = on
    netty.tcp {
      maximum-frame-size = 512000b
     //transport-class = "akka.remote.transport.netty.NettyTransport"
      hostname = "localhost"
      port = 14049
    }
  }
}
